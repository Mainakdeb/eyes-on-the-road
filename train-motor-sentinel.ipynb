{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tnrange, tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22424 entries, 0 to 22423\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subject    22424 non-null  object\n",
      " 1   classname  22424 non-null  object\n",
      " 2   img        22424 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 525.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22419</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_56936.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22420</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_46218.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22421</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_25946.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22422</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_67850.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22423</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_9684.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22424 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject classname            img\n",
       "0        p002        c0  img_44733.jpg\n",
       "1        p002        c0  img_72999.jpg\n",
       "2        p002        c0  img_25094.jpg\n",
       "3        p002        c0  img_69092.jpg\n",
       "4        p002        c0  img_92629.jpg\n",
       "...       ...       ...            ...\n",
       "22419    p081        c9  img_56936.jpg\n",
       "22420    p081        c9  img_46218.jpg\n",
       "22421    p081        c9  img_25946.jpg\n",
       "22422    p081        c9  img_67850.jpg\n",
       "22423    p081        c9   img_9684.jpg\n",
       "\n",
       "[22424 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_path='./state-farm-distracted-driver-detection_old/driver_imgs_list.csv'\n",
    "kaggle_path='../input/state-farm-distracted-driver-detection/driver_imgs_list.csv'\n",
    "df=pd.read_csv(local_path)\n",
    "print(df.info())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0    2489\n",
      "c3    2346\n",
      "c4    2326\n",
      "c6    2325\n",
      "c2    2317\n",
      "c5    2312\n",
      "c1    2267\n",
      "c9    2129\n",
      "c7    2002\n",
      "c8    1911\n",
      "Name: classname, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"classname\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df, cls):\n",
    "    max_size = df[cls].value_counts().max()\n",
    "    lst = [df]\n",
    "    for class_index, group in df.groupby(cls):\n",
    "        lst.append(group.sample(max_size-len(group), replace=True))\n",
    "    frame_new = pd.concat(lst)\n",
    "    df2=frame_new\n",
    "    df3=df2.sample(frac=1) # randomise\n",
    "    return(df3)\n",
    "\n",
    "df = balance_df(df, 'classname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c2    2489\n",
       "c4    2489\n",
       "c0    2489\n",
       "c9    2489\n",
       "c5    2489\n",
       "c3    2489\n",
       "c7    2489\n",
       "c8    2489\n",
       "c1    2489\n",
       "c6    2489\n",
       "Name: classname, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"classname\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_nparray(path):\n",
    "    i = plt.imread(path)    \n",
    "    return(np.array(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C_Dataset(Dataset):\n",
    "    \"\"\"custom\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file_path, root_dir, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        self.d = pd.read_csv(csv_file_path, header= None)[1:]\n",
    "    \n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        smol_img_path = str(self.d.iloc[idx][3])\n",
    "        class_name = str(self.d.iloc[idx][2])[-1] #only the number\n",
    "        full_img_path = self.root_dir + '/' + 'c'+ class_name + '/' + smol_img_path\n",
    "        img_arr = image_to_nparray(full_img_path)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_arr = self.transform(img_arr)\n",
    "        \n",
    "        return torch.tensor(int(class_name)), img_arr    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24890\n"
     ]
    }
   ],
   "source": [
    "local_train_path='./state-farm-distracted-driver-detection_old/imgs/train'\n",
    "\n",
    "kaggle_train_path='../input/state-farm-distracted-driver-detection/imgs/train'\n",
    "\n",
    "data = C_Dataset('balanced.csv', \n",
    "               local_train_path,\n",
    "                transform = transforms.Compose([\n",
    "                                                transforms.ToPILImage(),\n",
    "                                                transforms.Resize((150,150), interpolation=2),\n",
    "                                                transforms.RandomRotation(10),\n",
    "                                                transforms.ToTensor()\n",
    "                                                ])\n",
    "                )\n",
    "\n",
    "print(len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
